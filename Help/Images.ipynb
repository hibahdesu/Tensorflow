{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415e343a",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da8eaa",
   "metadata": {},
   "source": [
    "### Loading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data  # To load the MNIST digit dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(X_train)} images in the training dataset\")\n",
    "print(f\"There are {len(X_test)} images in the test dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of one image\n",
    "X_train[99].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d352dbd",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b823bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[99], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "sns.heatmap(X_train[9], annot=True, cmap=\"gray\", fmt=\".3g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    idx = np.random.randint(0, len(X_train))\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(y_train[idx])\n",
    "    ax.imshow(X_train[idx], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc30126",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5791ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[342].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[9].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac960a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image pixels\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[9].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58997afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[9].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[9], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccadcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63372b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(X_train, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, 3)\n",
    "X_test = np.expand_dims(X_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de62a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c52617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test = to_categorical(y_test, 10)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e63bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32a928",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ad262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=15,\n",
    "            validation_data=validation_generator,\n",
    "            verbose=2\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = layers.Flatten()(last_output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(pre_trained_model.input, x)\n",
    "\n",
    "    model.compile(optimizer=RMSprop(lr=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=3,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3caebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model\n",
    "model_for_aug = create_model()\n",
    "\n",
    "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
    "# the image, we also rotate and do other operations\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "# Train the new model\n",
    "history_with_aug = model_for_aug.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7f3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "881958b2",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation=\"relu\")\n",
    ")  # stride = 1, padding = valid\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))  # stride = pool size, padding = valid\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "#This for categorical, if it is binary, i have to change it to it\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "#For binary\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e984013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(\n",
    "    Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        input_shape=image_shape,\n",
    "        activation=\"relu\",\n",
    "    )\n",
    ")\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(128))\n",
    "model3.add(Activation(\"relu\"))\n",
    "\n",
    "model3.add(Dense(128))\n",
    "model3.add(Activation(\"relu\"))\n",
    "\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(\n",
    "    Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        input_shape=image_shape,\n",
    "        activation=\"relu\",\n",
    "    )\n",
    ")\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "model4.add(Dense(128))\n",
    "model4.add(Activation(\"relu\"))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Dense(128))\n",
    "model4.add(Activation(\"relu\"))\n",
    "\n",
    "model4.add(Dense(1))\n",
    "model4.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model4.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77918399",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bda35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bdce1",
   "metadata": {},
   "source": [
    "# EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a99cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", mode=\"max\", patience=4, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64329ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411da7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With validation data\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d5b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(model.history.history)\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8129247f",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457fbf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[[\"loss\", \"val_loss\"]].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[[\"accuracy\", \"val_accuracy\"]].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f611e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10021439",
   "metadata": {},
   "source": [
    "# Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    multilabel_confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c328a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8364ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    annot=True,\n",
    "    cmap=\"Blues\",\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"black\",\n",
    "    fmt=\"g\",\n",
    "    annot_kws={\"size\": 15},\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96463a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model3.evaluate(val_image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072238e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b98c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
